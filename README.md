# Python
requests_1 中代码可直接运行，也可以根据自己不同的需要修改正则表达式的内容，在爬取最后几个高校信息时有误，极个别特例可以忽略。

selenium_1 需要自己配置 selenium 和浏览器环境，在 send_keys 中写入自己淘宝的账号和密码，还可以更改 keyword 爬取不同的信息。

Ajax_1 分析中可以自己定义爬取图片的关键字和图片存储路径。

scrapy_1 只写出了爬虫的部分内容，框架的其余信息读者自行补充，用来爬取 itcast 的老师信息。

scrapy_2 用来爬取阳光热线问政平台的所有问政信息。

scrapy&selenium详细介绍了在scrapy中使用selenium爬取字节跳动职位信息的整个过程。
